{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = []\n",
    "for i in os.listdir('data/'):\n",
    "    if i.endswith('.txt'):\n",
    "        files.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.txt\n",
      "2.txt\n",
      "5.txt\n",
      "1.txt\n",
      "4.txt\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['dialogue'])\n",
    "for i in files:\n",
    "    print(i)\n",
    "    df_loop = pd.read_table('data/'+i, sep=\"\\n\", header=None)\n",
    "    df_loop = df_loop.rename(columns={0:'dialogue'})\n",
    "    df = df.append(df_loop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phoebe :   hi guys !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all :  hey ,  pheebs !  hi !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        dialogue\n",
       "0          phoebe :   hi guys ! \n",
       "1  all :  hey ,  pheebs !  hi ! "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def delete_blank(x):\n",
    "    if x=='':\n",
    "        return None\n",
    "    else:\n",
    "        return x\n",
    "df.dialogue = df.dialogue.map(delete_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_parentheses(x):\n",
    "    return re.sub(r'\\(.*\\)|\\[.*\\]', '', x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dialogue = df.dialogue.map(lambda x: delete_parentheses(x))\n",
    "df.dialogue = df.dialogue.map(delete_blank)\n",
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punctuation(x):\n",
    "    x = re.sub(r'\\.',' . ', x)\n",
    "    x = re.sub(r'\\,',' , ', x)\n",
    "    x = re.sub(r'\\!',' ! ', x)\n",
    "    x = re.sub(r'\\?',' ? ', x)\n",
    "    x = re.sub(r'\\:',' : ', x) \n",
    "    return x\n",
    "\n",
    "def delete_large_spaces(x):\n",
    "    return re.sub(r'\\s{2,}', ' ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dialogue = df.dialogue.map(lambda x: separate_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dialogue = df.dialogue.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_apostrophe(x):\n",
    "    x = re.sub(\"let's\", 'let us', x)\n",
    "    x = re.sub(\"c'mon\", 'come on', x)\n",
    "    x = re.sub(\"there's\", 'there is', x)\n",
    "    x = re.sub(\"you're\", 'you are', x)\n",
    "    x = re.sub(\"we're\", 'we are', x)\n",
    "    x = re.sub(\"i'm\", 'i am', x)\n",
    "    x = re.sub(\"y'\", 'you', x)\n",
    "    x = re.sub(\"how'd\", 'how did', x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dialogue = df.dialogue.map(change_apostrophe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_no_dialogue(x):\n",
    "    if ':' in x:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dialogue = df.dialogue.map(delete_no_dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open glove and tokenize-pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print( \"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "model_glove = loadGloveModel('../glove/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_df = pd.DataFrame(model_glove).T\n",
    "\n",
    "unk_pad_df = pd.DataFrame(columns=glove_df.columns)\n",
    "unk_pad_df.loc['<PAD>'] = np.zeros(glove_df.shape[1])\n",
    "unk_pad_df.loc['<UNK>'] = glove_df.mean()\n",
    "\n",
    "glove_unk_df = pd.concat([unk_pad_df,glove_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for memory reasons, use just the vocabulary from friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_string = list(df.as_matrix().flatten())\n",
    "vocab_friends = pd.Series(''.join(script_string).split()).drop_duplicates().reset_index(drop=True)\n",
    "vocab_friends = pd.Series(['<PAD>', '<UNK>']).append(vocab_friends)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_unk_friends_df = glove_unk_df[glove_unk_df.index.isin(vocab_friends)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_df = pd.DataFrame(glove_unk_friends_df.index, columns=['voc']).reset_index()\n",
    "voc_df.voc = voc_df.voc.str.lower()\n",
    "voc_df = voc_df.set_index('voc')\n",
    "voc_dic = voc_df.to_dict()['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "class TokenizerCustom(Tokenizer):\n",
    "    def __init__(self, voc, max_len=30, *args, **kwargs):\n",
    "        super(TokenizerCustom, self).__init__(*args, **kwargs)\n",
    "        self.max_len = max_len\n",
    "        self.word_index = voc\n",
    "        self.oov_token = '<unk>'\n",
    "        self.filters = '#$%&()*+-/<=>@[\\]^_`{|}~'\n",
    "    \n",
    "    def pad_string(self, x):\n",
    "        return pad_sequences(x, maxlen=self.max_len)\n",
    "    \n",
    "    def tokenize_string(self, x):\n",
    "        tok_str = self.texts_to_sequences(pd.Series(x).values)\n",
    "        return self.pad_string(tok_str)[0]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test unk\n",
    "tc = TokenizerCustom(voc=voc_dic, oov_token = voc_dic['<unk>'])\n",
    "tc.tokenize_string(\"skdjfnjf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok = df.copy()\n",
    "df_tok.dialogue = df_tok.dialogue.map(lambda x: tc.tokenize_string(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tok.dialogue[:len(df_tok)-1]\n",
    "X = np.array(X.tolist())\n",
    "y = df_tok.shift(-1).dialogue[:len(df_tok)-1]\n",
    "y = np.array(y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = len(X[0])\n",
    "emb_dim = glove_unk_friends_df.shape[1]\n",
    "vocab_dim = glove_unk_friends_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = np.array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], vocab_size, sequences.shape[1])\n",
    "    return y\n",
    "\n",
    "y_enc = encode_output(y, vocab_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " (1673, 30) but got array with shape (1290, 1673)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1290, 30, 1673)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_enc.shape\n",
    "(1673, 30) but got array with shape (30, 1673)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Dense, LSTM, Dropout, RepeatVector, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "inp = Input(shape=(max_seq_len,))\n",
    "emb = Embedding(vocab_dim, emb_dim, weights=[glove_unk_friends_df], \n",
    "                input_length=max_seq_len, trainable=False)(inp)\n",
    "lstm_in = LSTM(20)(emb)\n",
    "rep_vec = RepeatVector(vocab_dim)(lstm_in)\n",
    "lstm_out = LSTM(20, return_sequences=True)(rep_vec)\n",
    "out = TimeDistributed(Dense(max_seq_len, activation='softmax'))(lstm_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='acc', min_delta=0.0011, patience=5)\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_11 (Embedding)     (None, 30, 100)           167300    \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 20)                9680      \n",
      "_________________________________________________________________\n",
      "repeat_vector_7 (RepeatVecto (None, 1673, 20)          0         \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 1673, 20)          3280      \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 1673, 30)          630       \n",
      "=================================================================\n",
      "Total params: 180,890\n",
      "Trainable params: 13,590\n",
      "Non-trainable params: 167,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1290/1290 [==============================] - 32s 25ms/step - loss: 0.0596 - acc: 0.0057\n",
      "Epoch 2/100\n",
      "1290/1290 [==============================] - 31s 24ms/step - loss: 0.0593 - acc: 0.0328\n",
      "Epoch 3/100\n",
      "1290/1290 [==============================] - 33s 25ms/step - loss: 0.0593 - acc: 0.0521\n",
      "Epoch 4/100\n",
      "1290/1290 [==============================] - 32s 25ms/step - loss: 0.0609 - acc: 0.8682\n",
      "Epoch 5/100\n",
      " 256/1290 [====>.........................] - ETA: 22s - loss: 0.0603 - acc: 0.9829"
     ]
    }
   ],
   "source": [
    "model.fit(X, y_enc, epochs = 100, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1290, 30, 1673)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[0].reshape(-1,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
