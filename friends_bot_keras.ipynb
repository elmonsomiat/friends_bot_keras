{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = []\n",
    "for i in os.listdir('data/'):\n",
    "    if i.endswith('.txt'):\n",
    "        files.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.txt\n",
      "10.txt\n",
      "2_17.txt\n",
      "21.txt\n",
      "2_18.txt\n",
      "11.txt\n",
      "2_22.txt\n",
      "2.txt\n",
      "2_24.txt\n",
      "5.txt\n",
      "2_16.txt\n",
      "2_11.txt\n",
      "2_6.txt\n",
      "15.txt\n",
      "2_4.txt\n",
      "19.txt\n",
      "13.txt\n",
      "2_20.txt\n",
      "1.txt\n",
      "2_1.txt\n",
      "2_9.txt\n",
      "6.txt\n",
      "20.txt\n",
      "24.txt\n",
      "23.txt\n",
      "2_14.txt\n",
      "2_3.txt\n",
      "14.txt\n",
      "8.txt\n",
      "12.txt\n",
      "2_19.txt\n",
      "2_12.txt\n",
      "2_23.txt\n",
      "2_21.txt\n",
      "16.txt\n",
      "2_7.txt\n",
      "2_5.txt\n",
      "7.txt\n",
      "17.txt\n",
      "22.txt\n",
      "2_2.txt\n",
      "9.txt\n",
      "18.txt\n",
      "4.txt\n",
      "2_15.txt\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['dialogue'])\n",
    "for i in files:\n",
    "    print(i)\n",
    "    df_loop = pd.read_table('data/'+i, sep=\"\\n\", header=None)\n",
    "    df_loop = df_loop.rename(columns={0:'dialogue'})\n",
    "    df = df.append(df_loop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phoebe: (entering) Hi guys!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All: Hey, Pheebs! Hi!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      dialogue\n",
       "0  Phoebe: (entering) Hi guys!\n",
       "1        All: Hey, Pheebs! Hi!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def delete_blank(x):\n",
    "    if x=='':\n",
    "        return None\n",
    "    else:\n",
    "        return x\n",
    "df.dialogue = df.dialogue.map(delete_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_parentheses(x):\n",
    "    return re.sub(r'\\(.*\\)|\\[.*\\]', '', x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dialogue = df.dialogue.map(lambda x: delete_parentheses(x))\n",
    "df.dialogue = df.dialogue.map(delete_blank)\n",
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punctuation(x):\n",
    "    x = re.sub(r'\\.',' . ', x)\n",
    "    x = re.sub(r'\\,',' , ', x)\n",
    "    x = re.sub(r'\\!',' ! ', x)\n",
    "    x = re.sub(r'\\?',' ? ', x)\n",
    "    x = re.sub(r'\\:',' : ', x) \n",
    "    return x\n",
    "\n",
    "def delete_large_spaces(x):\n",
    "    return re.sub(r'\\s{2,}', ' ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dialogue = df.dialogue.map(lambda x: separate_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dialogue = df.dialogue.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_apostrophe(x):\n",
    "    x = re.sub(\"let's\", 'let us', x)\n",
    "    x = re.sub(\"c'mon\", 'come on', x)\n",
    "    x = re.sub(\"there's\", 'there is', x)\n",
    "    x = re.sub(\"you're\", 'you are', x)\n",
    "    x = re.sub(\"we're\", 'we are', x)\n",
    "    x = re.sub(\"i'm\", 'i am', x)\n",
    "    x = re.sub(\"y'\", 'you', x)\n",
    "    x = re.sub(\"how'd\", 'how did', x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dialogue = df.dialogue.map(change_apostrophe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_no_dialogue(x):\n",
    "    if ':' in x:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phoebe :   hi guys !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all :  hey ,  pheebs !  hi !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ross :  hey .  oh ,  oh ,  how did it go ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phoebe :  um ,  not so good .  he walked me to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all :  ohh .  ouch .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue\n",
       "0                              phoebe :   hi guys ! \n",
       "1                      all :  hey ,  pheebs !  hi ! \n",
       "2        ross :  hey .  oh ,  oh ,  how did it go ? \n",
       "3  phoebe :  um ,  not so good .  he walked me to...\n",
       "4                              all :  ohh .  ouch . "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dialogue = df.dialogue.map(delete_no_dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open glove and tokenize-pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print( \"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "model_glove = loadGloveModel('../glove/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_df = pd.DataFrame(model_glove).T\n",
    "\n",
    "unk_pad_df = pd.DataFrame(columns=glove_df.columns)\n",
    "unk_pad_df.loc['<PAD>'] = np.zeros(glove_df.shape[1])\n",
    "unk_pad_df.loc['<UNK>'] = glove_df.mean()\n",
    "\n",
    "glove_unk_df = pd.concat([unk_pad_df,glove_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for memory reasons, use just the vocabulary from friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_string = list(df.as_matrix().flatten())\n",
    "vocab_friends = pd.Series(''.join(script_string).split()).drop_duplicates().reset_index(drop=True)\n",
    "vocab_friends = pd.Series(['<PAD>', '<UNK>']).append(vocab_friends)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_unk_friends_df = glove_unk_df[glove_unk_df.index.isin(vocab_friends)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_df = pd.DataFrame(glove_unk_friends_df.index, columns=['voc']).reset_index()\n",
    "voc_df.voc = voc_df.voc.str.lower()\n",
    "voc_df = voc_df.set_index('voc')\n",
    "voc_dic = voc_df.to_dict()['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "class TokenizerCustom(Tokenizer):\n",
    "    def __init__(self, voc, max_len=20, *args, **kwargs):\n",
    "        super(TokenizerCustom, self).__init__(*args, **kwargs)\n",
    "        self.max_len = max_len\n",
    "        self.word_index = voc\n",
    "        self.oov_token = '<unk>'\n",
    "        self.filters = '#$%&()*+-/<=>@[\\]^_`{|}~'\n",
    "    \n",
    "    def pad_string(self, x):\n",
    "        return pad_sequences(x, maxlen=self.max_len)\n",
    "    \n",
    "    def tokenize_string(self, x):\n",
    "        tok_str = self.texts_to_sequences(pd.Series(x).values)\n",
    "        return self.pad_string(tok_str)[0]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test unk\n",
    "tc = TokenizerCustom(voc=voc_dic, oov_token = voc_dic['<unk>'])\n",
    "tc.tokenize_string(\"skdjfnjf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok = df.copy()\n",
    "df_tok.dialogue = df_tok.dialogue.map(lambda x: tc.tokenize_string(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tok.dialogue[:len(df_tok)-1]\n",
    "X = np.array(X.tolist())\n",
    "y = df_tok.shift(-1).dialogue[:len(df_tok)-1]\n",
    "y = np.array(y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = len(X[0])\n",
    "emb_dim = glove_unk_friends_df.shape[1]\n",
    "vocab_dim = glove_unk_friends_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11243, 20)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b12a03188a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0my_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-b12a03188a9b>\u001b[0m in \u001b[0;36mencode_output\u001b[0;34m(sequences, vocab_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mylist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = np.array(ylist)\n",
    "    print(y.shape)\n",
    "    y = y.reshape(sequences.shape[0], vocab_size, sequences.shape[1])\n",
    "    return y\n",
    "\n",
    "y_enc = encode_output(y, vocab_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_enc = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = np.array(ylist)\n",
    "    print(y.shape)\n",
    "    return y\n",
    "\n",
    "y_enc = encode_output(y, vocab_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nrep_vec = RepeatVector(vocab_dim)(lstm_in)\\nlstm_out = LSTM(256, return_sequences=True)(rep_vec)\\nout = TimeDistributed(Dense(max_seq_len, activation='softmax'))(lstm_out)\\n\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Dense, LSTM, Dropout, RepeatVector, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "inp = Input(shape=(max_seq_len,))\n",
    "emb = Embedding(vocab_dim, emb_dim, weights=[glove_unk_friends_df], \n",
    "                input_length=max_seq_len, trainable=False)(inp)\n",
    "lstm_in = LSTM(200, return_sequences=True)(emb)\n",
    "\n",
    "lstm_out = LSTM(200)(lstm_in)\n",
    "#d1 = Dense(400, activation='relu')(lstm_out)\n",
    "#d2 = Dense(100, activation='relu')(d1)\n",
    "out  = Dense(max_seq_len, activation='relu')(lstm_out)\n",
    "\n",
    "'''\n",
    "\n",
    "rep_vec = RepeatVector(vocab_dim)(lstm_in)\n",
    "lstm_out = LSTM(256, return_sequences=True)(rep_vec)\n",
    "out = TimeDistributed(Dense(max_seq_len, activation='softmax'))(lstm_out)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='acc', min_delta=0.001, patience=5)\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 20, 100)           603800    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 20, 200)           240800    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                4020      \n",
      "=================================================================\n",
      "Total params: 1,169,420\n",
      "Trainable params: 565,620\n",
      "Non-trainable params: 603,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11243/11243 [==============================] - 23s 2ms/step - loss: 4004671.5198 - acc: 0.1614\n",
      "Epoch 2/100\n",
      "11243/11243 [==============================] - 26s 2ms/step - loss: 4002581.7714 - acc: 0.1614\n",
      "Epoch 3/100\n",
      "11243/11243 [==============================] - 27s 2ms/step - loss: 4000531.0105 - acc: 0.1614\n",
      "Epoch 4/100\n",
      "11243/11243 [==============================] - 26s 2ms/step - loss: 3998501.3919 - acc: 0.1614\n",
      "Epoch 5/100\n",
      "11243/11243 [==============================] - 25s 2ms/step - loss: 3996501.3889 - acc: 0.1614\n",
      "Epoch 6/100\n",
      "11243/11243 [==============================] - 22s 2ms/step - loss: 3994532.3058 - acc: 0.1614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34045866a0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y_enc, epochs = 100, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X[0].reshape(-1,50)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
