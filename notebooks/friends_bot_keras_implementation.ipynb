{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from friends_bot.glove_loader import GloveLoader\n",
    "from friends_bot.dialogue_cleaner import DialogueCleaner\n",
    "from friends_bot.data_cleaner import TokenizerCustom, remap_words_overall\n",
    "from friends_bot.model_trainer import define_model, compile_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_loader = GloveLoader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_unk_df = glove_loader.run_glove_loader('../glove/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Friend Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for i in os.listdir('data/'):\n",
    "    if i.endswith('.txt'):\n",
    "        files.append(i)\n",
    "\n",
    "df = pd.DataFrame(columns=['dialogue'])\n",
    "for i in files:\n",
    "    df_loop = pd.read_table('data/'+i, sep=\"\\n\", header=None)\n",
    "    df_loop = df_loop.rename(columns={0:'dialogue'})\n",
    "    df = df.append(df_loop)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.head(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_cleaner = DialogueCleaner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue = dialogue_cleaner.run_dialogue_cleaner(df.dialogue)\n",
    "answer = dialogue.shift(-1)\n",
    "\n",
    "dialogue = dialogue.astype(str)\n",
    "answer = answer.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the dictionaries to tokenise the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_string = list(dialogue.as_matrix().flatten())\n",
    "vocab_friends = pd.Series(pd.Series(''.join(script_string).split()).value_counts().index)\n",
    "vocab_friends = pd.Series(['<PAD>', '<UNK>', '<BEGIN>', '<END>']).append(vocab_friends)\n",
    "glove_unk_friends_df = glove_unk_df[glove_unk_df.index.isin(vocab_friends)]\n",
    "voc_df = pd.DataFrame(glove_unk_friends_df.index, columns=['voc']).reset_index()\n",
    "voc_df.voc = voc_df.voc.str.lower()\n",
    "voc_df = voc_df.set_index('voc')\n",
    "voc_dic = voc_df.to_dict()['index']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers: Keep only the top 200 works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_words = 200\n",
    "script_string = list(answer.as_matrix().flatten())\n",
    "most_common_words = pd.Series(''.join(script_string).split()).value_counts().head(top_words)\n",
    "vocab_friends = pd.Series(most_common_words.index)\n",
    "vocab_friends = pd.Series(['<PAD>', '<UNK>', '<BEGIN>', '<END>']).append(vocab_friends)\n",
    "glove_unk_friends_ans_df = glove_unk_df[glove_unk_df.index.isin(vocab_friends)]\n",
    "voc_df = pd.DataFrame(glove_unk_friends_ans_df.index, columns=['voc']).reset_index()\n",
    "voc_df.voc = voc_df.voc.str.lower()\n",
    "voc_df = voc_df.set_index('voc')\n",
    "\n",
    "voc_dic_ans = voc_df.to_dict()['index']\n",
    "voc_dic_inv = {voc_dic_ans[x]:x for x in voc_dic_ans}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tok = TokenizerCustom(voc_dic)\n",
    "custom_tok_ans = TokenizerCustom(voc_dic_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dialogue.map(lambda x: custom_tok.tokenize_string(x))\n",
    "X = np.array(X.tolist())\n",
    "y = answer.map(lambda x: custom_tok_ans.tokenize_string(x))\n",
    "y = np.array(y.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remap most common words into different ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_dic_inv_copy = voc_dic_inv.copy()\n",
    "counts_ser = pd.Series(y.flatten()).value_counts()\n",
    "data_words = pd.Series(y.flatten()).value_counts().index\n",
    "min_count = pd.Series(y.flatten()).value_counts().iloc[-1]\n",
    "if min_count<10:\n",
    "    min_count = 10\n",
    "for i in range(len(data_words)):\n",
    "    word = data_words[i]\n",
    "    y, voc_dic_inv = remap_words_overall(y, int(counts_ser.loc[word]/min_count), word, voc_dic_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = len(X[0])\n",
    "emb_dim = glove_unk_friends_df.shape[1]\n",
    "vocab_dim = glove_unk_friends_df.shape[0]\n",
    "vocab_out_dim = y.flatten().max()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, out = define_model(max_seq_len, vocab_dim, vocab_out_dim, emb_weights=glove_unk_friends_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compile_model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='acc', min_delta=0.00001, patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='acc', factor=0.4, patience=5, min_lr=0.0005, verbose=1)\n",
    "model.fit([X], [y.reshape(y.shape[0] , y.shape[1], 1)], nb_epoch=1000, batch_size=32, shuffle=True,\\\n",
    "           callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
